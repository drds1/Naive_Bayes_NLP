{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Natural Language Processing\n",
    "\n",
    "This article will perform sentiment analysis on a series of tweets.\n",
    "Some of which pertain to natural disaster / terrorist incidents\n",
    "(class 1), the others are innocent drivel (class 0).\n",
    "\n",
    "In this post we will learn\n",
    "\n",
    "1): What is a Naive Bayes classifier.\n",
    "\n",
    "2): Implementation in Python\n",
    "\n",
    "3): Review Performance\n",
    "\n",
    "##  Naive Bayes Probabilities\n",
    "\n",
    "Training a model to label a sample of text as positive / negative\n",
    "is known as Natural Language Processing (NLP) binary classification.\n",
    "\n",
    "A common choice of model for such a task is the Naive Bayes classifier.\n",
    "Using [Bayes Theorem](https://medium.com/@theflyingmantis/text-classification-in-nlp-naive-bayes-a606bf419f8c\n",
    "),\n",
    "we can formulate our outcome variable as the probability of a certain class 1 or 2 given some input text X. In maths speak this is P(C_j | X).  We can calculate this from Bayes theorem as\n",
    "\n",
    "P(C_j | X) = P(X | C_j) P(C_j) / P(X).\n",
    "\n",
    "From the above, we have three quantities to calculate.\n",
    "\n",
    "#### __P(X)__: \n",
    "\n",
    "Give that all probabilities have P(X) as the denominator, this constant can be disregarded.\n",
    "\n",
    "#### __P(C_j):__ \n",
    "\n",
    "This is simple enough. It is just the relative\n",
    "fraction of class _i_ in the data set (i.e.\n",
    "for the positive class, this is the number of\n",
    "positives divided by the total number of samples\n",
    "in the training data).\n",
    "\n",
    "#### __P(X | C_j):__\n",
    "\n",
    "Representing the input as a set of features\n",
    "x1, x2 ...xn, P(X) = P(x1, x2...xn).\n",
    "We can rewrite P(X | C_j) as P(x1,x2...xn | C_j).\n",
    "Now comes the trick. The word _Naive_ in Naive Bayes\n",
    "classifiers means that we make the assumption that\n",
    "probabilities of all words are independent of\n",
    "each other. This chiefly means that we assume\n",
    "the order of the words doesnt matter (an incorrect assumption\n",
    "but one that often doesnt introduce too much error), but\n",
    " also allows us to rewrite our conditional\n",
    " probability as\n",
    "\n",
    "P(x1,x2...xn | C_j) = P(x1|C_j) P(x2 | C_j) .... P(xn | C_j).\n",
    "\n",
    "The probability of word 1 given class j, P(x1 | C_j), is then\n",
    "\n",
    "P(xi | C_j) = count (xi, C_j) / sum_k (xk, C_j).\n",
    "\n",
    "i.e. this counts all occurrences of word xi in\n",
    "all inputs of class C_j and divides them by the\n",
    "sum of counts of all words in the vocabulary.\n",
    "Laplace smoothing can be used to mitigate the\n",
    "effects of zero occurrences of words and\n",
    "dividing by zero.\n",
    "\n",
    "In summary, the Naive Bayes probability for\n",
    "input X, P(X | C_j) P(C_j), is calculated by\n",
    "multiplying together P(xi | C_j) for all words\n",
    "in our vocabulary and multiplying the result by\n",
    "P(C_J). Lets now set one up using sci-kit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn implementation:\n",
    "\n",
    "Python's scitkit-learn module includes excellent Naive Bayes functionality for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}